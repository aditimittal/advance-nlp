{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcNvt5jvyy6r",
        "outputId": "c727e90d-894c-4b92-dd6a-e678d80af5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of word types: 55, number of word tokens:83\n"
          ]
        }
      ],
      "source": [
        "para = '''There had to be a better way. That's all Nancy could think as she sat at her desk staring at her computer screen. She'd already spent five years of her life in this little cubicle staring at her computer doing \"work\" that didn't seem to matter to anyone including her own boss. There had to be more to her life than this and there had to be a better way to make a living. That's what she was thinking when the earthquake struck.'''.lower() # lowercase normalization is often useful in NLP\n",
        "\n",
        "types = 0\n",
        "tokens = 0\n",
        "\n",
        "splitted_words = para.split()\n",
        "splitted_words_set = set()\n",
        "tokens = len(splitted_words)\n",
        "for word in splitted_words:\n",
        "  splitted_words_set.add(word)\n",
        "types = len(splitted_words_set)  \n",
        "   \n",
        "\n",
        "print('Number of word types: %d, number of word tokens:%d' % (types, tokens))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This shows that types are the distinct words in a corpus, whereas tokens are all the words including repeats."
      ],
      "metadata": {
        "id": "bX-X2_GDzXkT"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}